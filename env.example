# Example env file for TgCrawler
# Copy to .env and edit as needed

# Directory used by docker-compose mounts (example requested)
DATA_DIR=./.meta/data

# Postgres credentials (defaults used in current compose)
POSTGRES_USER=tgcrawler
POSTGRES_PASSWORD=tgcrawler
POSTGRES_DB=tgcrawler

# App configuration
NODE_ENV=production
PORT=3000
HOST=0.0.0.0
TZ=Europe/Moscow

# Example DATABASE_URL (used by Prisma/Node app)
DATABASE_URL=postgresql://tgcrawler:tgcrawler@postgres:5432/tgcrawler

# Notes:
# 1) Copy this file to .env:  cp env.example .env  (or copy manually on Windows)
# 2) Then run: docker-compose up -d
# 3) To inspect scraped tasks from the database (UTF-8 output):
#    docker-compose exec postgres psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "SELECT id_post, title, description FROM tasks ORDER BY created_at DESC LIMIT 200;"
# 4) On Windows PowerShell, ensure UTF-8 output before running curl commands:
#    [Console]::OutputEncoding = [System.Text.Encoding]::UTF8
#    $res = curl.exe -s http://localhost:3000/api/tasks; $res | Out-File tasks.json -Encoding utf8; Get-Content tasks.json -Raw
# 5) If containers are not running, start them first: docker-compose up -d
# 6) If you want, I can run the DB query and show sample rows here.
